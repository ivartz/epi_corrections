{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is run within the docker environment https://github.com/ivartz/time-series-to-synthetic-biomaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify relative path to epi_corrections output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../epi_corrections_out_2019_06_19_372114315'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_directory_suffix = \"2019_06_19_372114315\"\n",
    "corrections_base_directory = \"../../../epi_corrections_out_\" + output_directory_suffix\n",
    "corrections_base_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install additional dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): nibabel in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.8 in /usr/local/lib/python3.5/dist-packages (from nibabel)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.3 in /usr/local/lib/python3.5/dist-packages (from nibabel)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nibabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for loading nifti files, processing and visualization in spimagine\n",
    "https://github.com/maweigert/spimagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gputools.core.ocldevice | prefered platform/device (0/0) not available (device type = 4) \n",
      "...choosing the best from the rest\n",
      "/usr/local/lib/python3.5/dist-packages/pyopencl/__init__.py:235: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  \"to see more.\", CompilerWarning)\n",
      "WARNING:gputools.core.ocldevice | prefered platform/device (0/0) not available (device type = 4) \n",
      "...choosing the best from the rest\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from spimagine import volshow, volfig\n",
    "\n",
    "def load_nifti(file):\n",
    "    # Returns \n",
    "    # voxel data : numpy array\n",
    "    # voxel dimensions (x, y, z) : tuple(,,)\n",
    "    # nifti header : nibabel.nifti1.Nifti1Header\n",
    "    data_class = nib.load(file)\n",
    "    return data_class.get_fdata(), tuple(data_class.header[\"pixdim\"][1:4]), data_class.header\n",
    "\n",
    "def xyzt_to_tzyx(vol_xyzt):\n",
    "    vol_tyzx = np.swapaxes(vol_xyzt, 0, 3)\n",
    "    vol_tzyx = np.swapaxes(vol_tyzx, 1, 2)\n",
    "    \n",
    "    # Return data with reverse x axis\n",
    "    return vol_tzyx[:,:,:,::-1]\n",
    "\n",
    "def xyz_to_zyx(vol_xyz):\n",
    "    vol_zyx = np.swapaxes(vol_xyz, 0, 2)\n",
    "    \n",
    "    # Return data with reverse x axis\n",
    "    return vol_zyx[:,:,::-1]\n",
    "\n",
    "def spimagine_show_volume_numpy(numpy_array, stackUnits=(1, 1, 1)):\n",
    "    # Spimagine OpenCL volume renderer.\n",
    "    volfig()\n",
    "    spim_widget = \\\n",
    "    volshow(numpy_array, stackUnits=stackUnits, interpolation='nearest')\n",
    "    spim_widget.set_colormap(\"grays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load (SPM resliced) labels file (MNI space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_data, labels_dimensions_xyz, labels_header = \\\n",
    "load_nifti(corrections_base_directory + \"/rlabels_Neuromorphometrics.nii\")\n",
    "labels_data = xyz_to_zyx(labels_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify qt5 GUI backend for spimagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spimagine_show_volume_numpy(labels_data, stackUnits=labels_dimensions_xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find paths to Normalized Relative Cerebral Blood Volume files from Nordic ICE Perfusion analysis on non-corrected and corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw cbv e1 files:\n",
      "['../../../epi_corrections_out_2019_06_19_372114315/EPI_raw_DSC/372114315/DAY_0000/No_DeFacing_GE-SE_EPI_SSH_v1_32CH_V2_scan/145923_GE-SE_EPI_SSH_v1_32CH_V2_scan_1001_e1_perf/wr_coregest_Normalized rCBV map -Leakage corrected.nii']\n",
      "topup cbv e1 files:\n",
      "['../../../epi_corrections_out_2019_06_19_372114315/EPI_applytopup/372114315/DAY_0000/No_DeFacing_GE-SE_EPI_SSH_v1_32CH_V2_scan/145923_GE-SE_EPI_SSH_v1_32CH_V2_scan_1001_e1_prep_topup_applytopup_postp_perf/wr_coregest_Normalized rCBV map -Leakage corrected.nii']\n",
      "epic cbv e1 files:\n",
      "['../../../epi_corrections_out_2019_06_19_372114315/EPI_applyepic/372114315/DAY_0000/No_DeFacing_GE-SE_EPI_SSH_v1_32CH_V2_scan/145923_GE-SE_EPI_SSH_v1_32CH_V2_scan_1001_e1_applyepic_perf/wr_coregest_Normalized rCBV map -Leakage corrected.nii']\n",
      "raw cbv e2 files:\n",
      "['../../../epi_corrections_out_2019_06_19_372114315/EPI_raw_DSC/372114315/DAY_0000/No_DeFacing_GE-SE_EPI_SSH_v1_32CH_V2_scan/145923_GE-SE_EPI_SSH_v1_32CH_V2_scan_1001_e2_perf/wr_coregest_Normalized rCBV map -Leakage corrected.nii']\n",
      "topup cbv e2 files:\n",
      "['../../../epi_corrections_out_2019_06_19_372114315/EPI_applytopup/372114315/DAY_0000/No_DeFacing_GE-SE_EPI_SSH_v1_32CH_V2_scan/145923_GE-SE_EPI_SSH_v1_32CH_V2_scan_1001_e2_prep_topup_applytopup_postp_perf/wr_coregest_Normalized rCBV map -Leakage corrected.nii']\n",
      "epic cbv e2 files:\n",
      "['../../../epi_corrections_out_2019_06_19_372114315/EPI_applyepic/372114315/DAY_0000/No_DeFacing_GE-SE_EPI_SSH_v1_32CH_V2_scan/145923_GE-SE_EPI_SSH_v1_32CH_V2_scan_1001_e2_applyepic_perf/wr_coregest_Normalized rCBV map -Leakage corrected.nii']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Spin Echo nrCBV (e1)\n",
    "\n",
    "raw_cbv_files_e1 = \\\n",
    "[tuple3[0] + \"/wr_coregest_Normalized rCBV map -Leakage corrected.nii\" \\\n",
    " for tuple3 in os.walk(corrections_base_directory + \"/EPI_raw_DSC\") \\\n",
    " if (\"wr_coregest_Normalized rCBV map -Leakage corrected.nii\" in  tuple3[2] and \"_e1_\" in tuple3[0])]\n",
    "\n",
    "topup_cbv_files_e1 = \\\n",
    "[tuple3[0] + \"/wr_coregest_Normalized rCBV map -Leakage corrected.nii\" \\\n",
    " for tuple3 in os.walk(corrections_base_directory + \"/EPI_applytopup\") \\\n",
    " if (\"wr_coregest_Normalized rCBV map -Leakage corrected.nii\" in  tuple3[2] and \"_e1_\" in tuple3[0])]\n",
    "\n",
    "epic_cbv_files_e1 = \\\n",
    "[tuple3[0] + \"/wr_coregest_Normalized rCBV map -Leakage corrected.nii\" \\\n",
    " for tuple3 in os.walk(corrections_base_directory + \"/EPI_applyepic\") \\\n",
    " if (\"wr_coregest_Normalized rCBV map -Leakage corrected.nii\" in  tuple3[2] and \"_e1_\" in tuple3[0])]\n",
    "\n",
    "# Gradient Echo nrCBV (e2)\n",
    "\n",
    "raw_cbv_files_e2 = \\\n",
    "[tuple3[0] + \"/wr_coregest_Normalized rCBV map -Leakage corrected.nii\" \\\n",
    " for tuple3 in os.walk(corrections_base_directory + \"/EPI_raw_DSC\") \\\n",
    " if (\"wr_coregest_Normalized rCBV map -Leakage corrected.nii\" in  tuple3[2] and \"_e2_\" in tuple3[0])]\n",
    "\n",
    "topup_cbv_files_e2 = \\\n",
    "[tuple3[0] + \"/wr_coregest_Normalized rCBV map -Leakage corrected.nii\" \\\n",
    " for tuple3 in os.walk(corrections_base_directory + \"/EPI_applytopup\") \\\n",
    " if (\"wr_coregest_Normalized rCBV map -Leakage corrected.nii\" in  tuple3[2] and \"_e2_\" in tuple3[0])]\n",
    "\n",
    "epic_cbv_files_e2 = \\\n",
    "[tuple3[0] + \"/wr_coregest_Normalized rCBV map -Leakage corrected.nii\" \\\n",
    " for tuple3 in os.walk(corrections_base_directory + \"/EPI_applyepic\") \\\n",
    " if (\"wr_coregest_Normalized rCBV map -Leakage corrected.nii\" in  tuple3[2] and \"_e2_\" in tuple3[0])]\n",
    "\n",
    "print(\"raw cbv e1 files:\")\n",
    "print(raw_cbv_files_e1)\n",
    "print(\"topup cbv e1 files:\")\n",
    "print(topup_cbv_files_e1)\n",
    "print(\"epic cbv e1 files:\")\n",
    "print(epic_cbv_files_e1)\n",
    "print(\"raw cbv e2 files:\")\n",
    "print(raw_cbv_files_e2)\n",
    "print(\"topup cbv e2 files:\")\n",
    "print(topup_cbv_files_e2)\n",
    "print(\"epic cbv e2 files:\")\n",
    "print(epic_cbv_files_e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load nrCBV files into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Echo\n",
    "\n",
    "# Raw\n",
    "raw_cbv_data_e1 = []\n",
    "for file in raw_cbv_files_e1:\n",
    "    raw_cbv_data, raw_cbv_dimensions_xyz, raw_cbv_header = load_nifti(file)\n",
    "    # Swap axes for correct visualization\n",
    "    raw_cbv_data = xyz_to_zyx(raw_cbv_data)\n",
    "    \n",
    "    # Set nan to 0\n",
    "    raw_cbv_data[np.isnan(raw_cbv_data)] = 0\n",
    "    \n",
    "    #raw_cbv_data[raw_cbv_data > 25] = 0\n",
    "    #raw_cbv_data[raw_cbv_data < -5] = 0\n",
    "    \n",
    "    raw_cbv_data_e1 += [raw_cbv_data]\n",
    "raw_cbv_data_e1 = np.array(raw_cbv_data_e1)\n",
    "\n",
    "# TOPUP\n",
    "topup_cbv_data_e1 = []\n",
    "for file in topup_cbv_files_e1:\n",
    "\n",
    "    topup_cbv_data, topup_cbv_dimensions_xyz, topup_cbv_header = \\\n",
    "    load_nifti(file)\n",
    "    topup_cbv_data = xyz_to_zyx(topup_cbv_data)\n",
    "\n",
    "    # Set nan to 0\n",
    "    topup_cbv_data[np.isnan(topup_cbv_data)] = 0\n",
    "    #topup_cbv_data[topup_cbv_data > 25] = 0\n",
    "    #topup_cbv_data[topup_cbv_data < -5] = 0\n",
    "    \n",
    "    topup_cbv_data_e1 += [topup_cbv_data]\n",
    "topup_cbv_data_e1 = np.array(topup_cbv_data_e1)\n",
    "    \n",
    "# EPIC\n",
    "epic_cbv_data_e1 = []\n",
    "for file in epic_cbv_files_e1:\n",
    "\n",
    "    epic_cbv_data, epic_cbv_dimensions_xyz, epic_cbv_header = \\\n",
    "    load_nifti(file)\n",
    "    epic_cbv_data = xyz_to_zyx(epic_cbv_data)\n",
    "\n",
    "    # Set nan to 0\n",
    "    epic_cbv_data[np.isnan(epic_cbv_data)] = 0\n",
    "    #epic_cbv_data[epic_cbv_data > 25] = 0\n",
    "    #epic_cbv_data[epic_cbv_data < -5] = 0\n",
    "    \n",
    "    epic_cbv_data_e1 = [epic_cbv_data]\n",
    "epic_cbv_data_e1 = np.array(epic_cbv_data_e1)\n",
    "\n",
    "# Spin Echo\n",
    "\n",
    "# Raw\n",
    "raw_cbv_data_e2 = []\n",
    "for file in raw_cbv_files_e2:\n",
    "    raw_cbv_data, raw_cbv_dimensions_xyz, raw_cbv_header = load_nifti(file)\n",
    "    # Swap axes for correct visualization\n",
    "    raw_cbv_data = xyz_to_zyx(raw_cbv_data)\n",
    "    \n",
    "    # Set nan to 0\n",
    "    raw_cbv_data[np.isnan(raw_cbv_data)] = 0\n",
    "    \n",
    "    #raw_cbv_data[raw_cbv_data > 25] = 0\n",
    "    #raw_cbv_data[raw_cbv_data < -5] = 0\n",
    "    \n",
    "    raw_cbv_data_e2 += [raw_cbv_data]\n",
    "raw_cbv_data_e2 = np.array(raw_cbv_data_e2)\n",
    "\n",
    "# TOPUP\n",
    "topup_cbv_data_e2 = []\n",
    "for file in topup_cbv_files_e2:\n",
    "\n",
    "    topup_cbv_data, topup_cbv_dimensions_xyz, topup_cbv_header = \\\n",
    "    load_nifti(file)\n",
    "    topup_cbv_data = xyz_to_zyx(topup_cbv_data)\n",
    "\n",
    "    # Set nan to 0\n",
    "    topup_cbv_data[np.isnan(topup_cbv_data)] = 0\n",
    "    #topup_cbv_data[topup_cbv_data > 25] = 0\n",
    "    #topup_cbv_data[topup_cbv_data < -5] = 0\n",
    "    \n",
    "    topup_cbv_data_e2 += [raw_cbv_data]\n",
    "topup_cbv_data_e2 = np.array(topup_cbv_data_e2)\n",
    "    \n",
    "# EPIC\n",
    "epic_cbv_data_e2 = []\n",
    "for file in epic_cbv_files_e2:\n",
    "\n",
    "    epic_cbv_data, epic_cbv_dimensions_xyz, epic_cbv_header = \\\n",
    "    load_nifti(file)\n",
    "    epic_cbv_data = xyz_to_zyx(epic_cbv_data)\n",
    "\n",
    "    # Set nan to 0\n",
    "    epic_cbv_data[np.isnan(epic_cbv_data)] = 0\n",
    "    #epic_cbv_data[epic_cbv_data > 25] = 0\n",
    "    #epic_cbv_data[epic_cbv_data < -5] = 0\n",
    "    \n",
    "    epic_cbv_data_e2 += [epic_cbv_data]\n",
    "epic_cbv_data_e2 = np.array(epic_cbv_data_e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlabels_fraction = 15\\n\\nraw_cbv_data_e1_overlay = raw_cbv_data_e1[0] + (1/labels_fraction)*np.max(raw_cbv_data_e1[0])*labels_data/np.max(labels_data)\\ntopup_cbv_data_e1_overlay = topup_cbv_data_e1[0] + (1/labels_fraction)*np.max(topup_cbv_data_e1[0])*labels_data/np.max(labels_data)\\n\\nnum_repeat_volume = 10\\n\\nraw_vs_topup_cbv_data = np.append(          np.repeat(                    np.expand_dims(                                   raw_cbv_data_e1_overlay, axis=0),                     num_repeat_volume,                     axis=0),           np.repeat(                    np.expand_dims(                                   topup_cbv_data_e1_overlay, axis=0),                     num_repeat_volume,                     axis=0),           axis=0)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "labels_fraction = 15\n",
    "\n",
    "raw_cbv_data_e1_overlay = raw_cbv_data_e1[0] + (1/labels_fraction)*np.max(raw_cbv_data_e1[0])*labels_data/np.max(labels_data)\n",
    "topup_cbv_data_e1_overlay = topup_cbv_data_e1[0] + (1/labels_fraction)*np.max(topup_cbv_data_e1[0])*labels_data/np.max(labels_data)\n",
    "\n",
    "num_repeat_volume = 10\n",
    "\n",
    "raw_vs_topup_cbv_data = \\\n",
    "np.append(\\\n",
    "          np.repeat(\\\n",
    "                    np.expand_dims(\\\n",
    "                                   raw_cbv_data_e1_overlay, axis=0), \\\n",
    "                    num_repeat_volume, \\\n",
    "                    axis=0), \\\n",
    "          np.repeat(\\\n",
    "                    np.expand_dims(\\\n",
    "                                   topup_cbv_data_e1_overlay, axis=0), \\\n",
    "                    num_repeat_volume, \\\n",
    "                    axis=0), \\\n",
    "          axis=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spimagine_show_volume_numpy(epic_cbv_data_e1, stackUnits=labels_dimensions_xyz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
